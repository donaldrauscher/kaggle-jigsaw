{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re, yaml\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from distributed import Client\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.feature_extraction.text import strip_tags, strip_accents_ascii, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, ParameterGrid\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "from dask_ml.model_selection import RandomizedSearchCV as RandomizedSearchCVBase\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_train = pd.read_csv(\"data/train.csv\", encoding = \"utf-8\")\n",
    "df_test = pd.read_csv(\"data/train.csv\", encoding = \"utf-8\")\n",
    "df_train= df_train.head(10000)\n",
    "df_test= df_test.head(1000)\n",
    "yvar = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308017</td>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.262158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.308017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.364642</td>\n",
       "      <td>0.166033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.292142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>0.147546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.364642</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.262158</td>\n",
       "      <td>0.166033</td>\n",
       "      <td>0.292142</td>\n",
       "      <td>0.147546</td>\n",
       "      <td>0.353182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic   obscene    threat    insult  \\\n",
       "toxic          1.000000      0.308017  0.664821  0.163685  0.642155   \n",
       "severe_toxic   0.308017      1.000000  0.401400  0.133694  0.364642   \n",
       "obscene        0.664821      0.401400  1.000000  0.134702  0.714533   \n",
       "threat         0.163685      0.133694  0.134702  1.000000  0.131717   \n",
       "insult         0.642155      0.364642  0.714533  0.131717  1.000000   \n",
       "identity_hate  0.262158      0.166033  0.292142  0.147546  0.353182   \n",
       "\n",
       "               identity_hate  \n",
       "toxic               0.262158  \n",
       "severe_toxic        0.166033  \n",
       "obscene             0.292142  \n",
       "threat              0.147546  \n",
       "insult              0.353182  \n",
       "identity_hate       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "df_train[yvar].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.0971\n",
       "severe_toxic     0.0101\n",
       "obscene          0.0527\n",
       "threat           0.0033\n",
       "insult           0.0494\n",
       "identity_hate    0.0084\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[yvar].apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up W2V transformer\n",
    "class W2VTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, size = 100, **kwargs):\n",
    "        self.gensim_model = None\n",
    "        self.size = size\n",
    "        self.gensim_params = kwargs\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(doc):\n",
    "        doc = strip_tags(doc.lower())\n",
    "        doc = re.compile(r\"\\s\\s+\").sub(\" \", doc)\n",
    "        words = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(doc)\n",
    "        words = [w for w in words if w not in ENGLISH_STOP_WORDS]\n",
    "        return words\n",
    "    \n",
    "    @property\n",
    "    def base_vector(self):\n",
    "        return np.zeros(self.gensim_model.vector_size)\n",
    "    \n",
    "    def get_vector_word(self, word):\n",
    "        try:\n",
    "            return self.gensim_model[word]\n",
    "        except KeyError:\n",
    "            return self.base_vector\n",
    "\n",
    "    def get_vector_sentence(self, sentence):\n",
    "        if sentence:\n",
    "            vectors = np.array([self.get_vector_word(w) for w in sentence])\n",
    "            return vectors.mean(axis = 0)\n",
    "        else:\n",
    "            return self.base_vector\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        sentences = X.apply(self.tokenize)\n",
    "        self.gensim_model = Word2Vec(sentences = sentences, size = self.size, **self.gensim_params)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return np.vstack([self.get_vector_sentence(s) for s in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "xdata = df_train.comment_text\n",
    "ydata = df_train[yvar]\n",
    "xdata_train, xdata_eval, ydata_train, ydata_eval = train_test_split(xdata, ydata, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline\n",
    "def basic_stats(docs):\n",
    "    nwords = docs.apply(lambda x: len(x.split()))\n",
    "    nchar = docs.apply(len)\n",
    "    ncap = docs.apply(lambda x: len(re.compile(r\"[A-Z]\").findall(x)))\n",
    "    ncap_perc = ncap / nchar\n",
    "    nexcl = docs.apply(lambda x: len(re.compile(r\"!\").findall(x)))\n",
    "    nquest = docs.apply(lambda x: len(re.compile(r\"\\?\").findall(x)))\n",
    "    nsymb = docs.apply(lambda x: len(re.compile(r\"&|@|#|\\$|%|\\*|\\^\").findall(x)))\n",
    "    nsmile = docs.apply(lambda x: len(re.compile(r\"((?::|;|=)(?:-)?(?:\\)|D|P))\").findall(x)))\n",
    "    return pd.DataFrame(data = dict(\n",
    "        nwords = nwords, nchar = nchar, ncap = ncap, ncap_perc = ncap_perc,\n",
    "        nexcl = nexcl, nquest = nquest, nsymb = nsymb, nsmile = nsmile\n",
    "    ))\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('features', FeatureUnion(transformer_list = [\n",
    "        ('w2v', W2VTransformer()),\n",
    "        ('tfidf', TfidfVectorizer(min_df = 5, max_df = 0.5)),\n",
    "        ('kbest', Pipeline(steps = [\n",
    "            ('cv', CountVectorizer(min_df = 5, max_df = 0.5)),\n",
    "            ('kbest', SelectKBest())\n",
    "        ])),\n",
    "        ('stats', FunctionTransformer(func = basic_stats, validate = False))\n",
    "    ])),\n",
    "    #('model', XGBClassifier(seed = 1))\n",
    "    ('model', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the parameter grid\n",
    "pg1 = [\n",
    "    {'features__w2v__size': [500], 'features__tfidf__max_features': [1000], 'features__kbest__kbest__k': [1000]},\n",
    "    {'features__w2v__size': [1000], 'features__tfidf__max_features': [2000], 'features__kbest__kbest__k': [2000]},\n",
    "    {'features__w2v__size': [1000], 'features__tfidf__max_features': [3000], 'features__kbest__kbest__k': [3000]},\n",
    "]\n",
    "pg2 = {\n",
    "    'model__n_estimators': [250, 500, 1000, 2000],\n",
    "    'model__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3],\n",
    "    'model__max_depth': [2, 4, 6, 8, 10],\n",
    "    'model__min_child_weight': [5],\n",
    "    'model__subsample': [0.8],\n",
    "    'model__colsample_bytree': [0.8]\n",
    "}\n",
    "\n",
    "def merge_param_grids(x, y):\n",
    "    z = list(product(list(x), list(y)))\n",
    "    z = [dict(**i[0], **i[1]) for i in z]\n",
    "    listize = lambda x: dict(zip(x.keys(), [[i] for i in x.values()]))\n",
    "    z = [listize(i) for i in z]\n",
    "    return ParameterGrid(z)\n",
    "\n",
    "pg = merge_param_grids(ParameterGrid(pg1), ParameterGrid(pg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non-multimetric, don't require refit = True for best_params_ / best_score_\n",
    "class RandomizedSearchCV(RandomizedSearchCVBase):\n",
    "\n",
    "    # For multiple metric evaluation, refit is a string denoting the scorer that should be \n",
    "    # used to find the best parameters for refitting the estimator \n",
    "    @property\n",
    "    def scorer_key(self):\n",
    "        return self.refit if self.multimetric_ else 'score'\n",
    "    \n",
    "    @property\n",
    "    def best_index(self):\n",
    "        check_is_fitted(self, 'cv_results_')\n",
    "        return np.flatnonzero(self.cv_results_['rank_test_{}'.format(self.scorer_key)] == 1)[0]\n",
    "\n",
    "    @property\n",
    "    def best_params_(self):\n",
    "        return self.cv_results_['params'][self.best_index]\n",
    "\n",
    "    @property\n",
    "    def best_score_(self):\n",
    "        return self.cv_results_['mean_test_{}'.format(self.scorer_key)][self.best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "try:\n",
    "    with open('model_param.yaml', 'r') as f:\n",
    "        param_optimal = yaml.load(f)\n",
    "except IOError:\n",
    "    param_optimal = {}\n",
    "\n",
    "    # create tuner\n",
    "    client = Client()\n",
    "    ss = ShuffleSplit(n_splits = 5, train_size = 0.8, random_state = 1)\n",
    "    tuner = RandomizedSearchCV(pipeline, pg, scheduler = client, scoring = 'roc_auc', \n",
    "                               cv = ss, refit = False, return_train_score = False, random_state = 1, \n",
    "                               n_iter = 20)\n",
    "    \n",
    "#     # use tuner to determine optimal params\n",
    "#     %time tuner.fit(xdata_train, ydata_train)\n",
    "#     print('Best params: %s' % (str(tuner.best_params_)))\n",
    "#     print('Best params score: %s' % (str(tuner.best_score_)))\n",
    "\n",
    "#     # save best params\n",
    "#     param_optimal = tuner.best_params_\n",
    "#     with open('model_param.yaml', 'w') as f:\n",
    "#         yaml.dump(param_optimal, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with optimal param and generate predictions on eval set\n",
    "param_optimal = {\n",
    "    'features__w2v__size': 100,\n",
    "    'features__tfidf__max_features': 100,\n",
    "    'features__kbest__kbest__k': 100,\n",
    "    'model__C': 0.01,\n",
    "    'model__penalty': 'l2'\n",
    "#     'model__n_estimators': 100,\n",
    "#     'model__learning_rate': 0.3,\n",
    "#     'model__max_depth': 6,\n",
    "#     'model__min_child_weight': 5,\n",
    "#     'model__subsample': 0.8,\n",
    "#     'model__colsample_bytree': 0.8\n",
    "}\n",
    "pipeline.set_params(**param_optimal)\n",
    "\n",
    "models = client.map(lambda y: clone(pipeline).fit(xdata_train, ydata_train[y]), yvar)\n",
    "ydata_eval_pred = client.map(lambda m: pd.Series(m.predict_proba(xdata_eval)[:,1]), models)\n",
    "\n",
    "ydata_eval_pred = client.gather(ydata_eval_pred)\n",
    "ydata_eval_pred = pd.concat(ydata_eval_pred, axis = 1)\n",
    "ydata_eval_pred.columns = yvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCs: [0.8894434442270059, 0.7396385521090292, 0.8482838364167479, 0.7448743718592965, 0.8415090659891328, 0.7163947163947164]\n",
      "Avg AUC: 0.7966906644993214\n"
     ]
    }
   ],
   "source": [
    "# calculate performance on test set\n",
    "auc = [roc_auc_score(ydata_eval[y], ydata_eval_pred[y]) for y in yvar]\n",
    "print('Model AUCs: %s' % auc)\n",
    "print('Avg AUC: %s' % np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_test = df_test.comment_text\n",
    "\n",
    "models_final = client.map(lambda y: clone(pipeline).fit(xdata, ydata[y]), yvar)\n",
    "ydata_test_pred = client.map(lambda m: pd.Series(m.predict_proba(xdata_test)[:,1]), models_final)\n",
    "\n",
    "ydata_test_pred = client.gather(ydata_test_pred)\n",
    "ydata_test_pred = pd.concat(ydata_test_pred, axis = 1)\n",
    "ydata_test_pred.columns = yvar\n",
    "ydata_test_pred['id'] = df_test.id\n",
    "\n",
    "ydata_test_pred.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
