{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml, re, copy\n",
    "\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import strip_tags\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import distributed\n",
    "from dask_ml.model_selection import GridSearchCV as GridSearchCVBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "client_gcs = storage.Client()\n",
    "bucket = client_gcs.get_bucket('djr-data')\n",
    "\n",
    "def gcs_to_df(f):\n",
    "    blob = bucket.blob(f)\n",
    "    buf = BytesIO()\n",
    "    blob.download_to_file(buf)\n",
    "    buf.seek(0)\n",
    "    return pd.read_csv(buf, encoding = \"utf-8\")\n",
    " \n",
    "df_train = gcs_to_df(\"kaggle-jigsaw/train.csv\").head(10000)\n",
    "df_test = gcs_to_df(\"kaggle-jigsaw/test.csv\").head(10000)\n",
    "yvar = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize client for interacting with dask\n",
    "# DASK_SCHEDULER_ADDRESS env variable specifies scheduler ip\n",
    "client_dask = distributed.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308017</td>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.262158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.308017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.364642</td>\n",
       "      <td>0.166033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.292142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>0.147546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.364642</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.131717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.262158</td>\n",
       "      <td>0.166033</td>\n",
       "      <td>0.292142</td>\n",
       "      <td>0.147546</td>\n",
       "      <td>0.353182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic   obscene    threat    insult  \\\n",
       "toxic          1.000000      0.308017  0.664821  0.163685  0.642155   \n",
       "severe_toxic   0.308017      1.000000  0.401400  0.133694  0.364642   \n",
       "obscene        0.664821      0.401400  1.000000  0.134702  0.714533   \n",
       "threat         0.163685      0.133694  0.134702  1.000000  0.131717   \n",
       "insult         0.642155      0.364642  0.714533  0.131717  1.000000   \n",
       "identity_hate  0.262158      0.166033  0.292142  0.147546  0.353182   \n",
       "\n",
       "               identity_hate  \n",
       "toxic               0.262158  \n",
       "severe_toxic        0.166033  \n",
       "obscene             0.292142  \n",
       "threat              0.147546  \n",
       "insult              0.353182  \n",
       "identity_hate       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "df_train[yvar].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.0971\n",
       "severe_toxic     0.0101\n",
       "obscene          0.0527\n",
       "threat           0.0033\n",
       "insult           0.0494\n",
       "identity_hate    0.0084\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[yvar].apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "xdata = df_train.comment_text\n",
    "ydata = df_train[yvar]\n",
    "xdata_train, xdata_eval, ydata_train, ydata_eval = train_test_split(xdata, ydata, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return words from corpus\n",
    "# TODO: also try r\"([\\w][\\w']*\\w)\"\n",
    "def tokenize(doc, token=r\"(?u)\\b\\w\\w+\\b\"):\n",
    "    doc = strip_tags(doc.lower())\n",
    "    doc = re.compile(r\"\\s\\s+\").sub(\" \", doc)\n",
    "    words = re.compile(token).findall(doc)\n",
    "    return words\n",
    "\n",
    "# remove stop words\n",
    "def remove_stop_words(x, stop_words=ENGLISH_STOP_WORDS):\n",
    "    return [i for i in x if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returning basic stats about docs\n",
    "def basic_stats(docs):\n",
    "    nwords = docs.apply(lambda x: len(x.split()))\n",
    "    nchar = docs.apply(len)\n",
    "    ncap = docs.apply(lambda x: len(re.compile(r\"[A-Z]\").findall(x)))\n",
    "    ncap_perc = ncap / nchar\n",
    "    nexcl = docs.apply(lambda x: len(re.compile(r\"!\").findall(x)))\n",
    "    nsmile = docs.apply(lambda x: len(re.compile(r\"((?::|;|=)(?:-)?(?:\\)|D|P))\").findall(x)))\n",
    "    return pd.DataFrame(data = dict(\n",
    "        nwords_log = np.log(nwords),\n",
    "        ncap_perc = ncap_perc,\n",
    "        nexcl = np.clip(nexcl, 0, 5),\n",
    "        has_smile = (nsmile > 0).astype(int)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for gensim Phraser\n",
    "COMMON_TERMS = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "class PhraseTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, common_terms=COMMON_TERMS):\n",
    "        self.phraser = None\n",
    "        self.common_terms = common_terms\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        phrases = Phrases(X, common_terms=self.common_terms)\n",
    "        self.phraser = Phraser(phrases)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: self.phraser[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making tagged documents\n",
    "# NOTE: can't use FunctionTransformer since TransformerMixin doesn't pass y to fit_transform anymore\n",
    "class MakeTaggedDocuments(BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if y is not None:\n",
    "            yvar = list(y.columns)\n",
    "            tags = y.apply(lambda row: [i for i,j in zip(yvar, row) if j == 1], axis=1)\n",
    "            return [TaggedDocument(words=w, tags=t) for w,t in zip(X, tags)]\n",
    "        else:\n",
    "            return [TaggedDocument(words=w, tags=[]) for w in X]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for gensim Doc2Vec\n",
    "class D2VEstimator(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, min_count=10, alpha=0.025, vector_size=200, epochs=20):\n",
    "        self.min_count = min_count\n",
    "        self.alpha = alpha\n",
    "        self.vector_size = vector_size\n",
    "        self.epochs = epochs\n",
    "        self.model = Doc2Vec(seed=1, hs=1, negative=0, dbow_words=0, dm=0, min_alpha=0.0001,\n",
    "                             min_count=self.min_count, alpha=self.alpha, vector_size=self.vector_size, epochs=self.epochs)\n",
    "\n",
    "    def get_tags(self, doc):\n",
    "        vec = self.model.infer_vector(doc.words, self.model.alpha, self.model.min_alpha, self.model.epochs)\n",
    "        return dict(self.model.docvecs.most_similar([vec]))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.model.build_vocab(X)\n",
    "        self.model.train(X, epochs=self.model.epochs, total_examples=self.model.corpus_count)\n",
    "        self.model.delete_temporary_training_data()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        pred = [self.get_tags(d) for d in X]\n",
    "        pred = pd.DataFrame.from_records(data=pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('fe', FeatureUnion(transformer_list=[\n",
    "        ('d2v', Pipeline(steps=[\n",
    "            ('tk', FunctionTransformer(func=lambda x: x.apply(tokenize), validate=False)),\n",
    "            ('ph', PhraseTransformer()),\n",
    "            ('sw', FunctionTransformer(func=lambda x: x.apply(remove_stop_words), validate=False)),\n",
    "            ('doc', MakeTaggedDocuments()),\n",
    "            ('d2v', D2VEstimator())\n",
    "        ])),\n",
    "        ('bs', FunctionTransformer(func=basic_stats, validate=False))\n",
    "    ])),\n",
    "    ('ovr', OneVsRestClassifier(LogisticRegression(class_weight=\"balanced\")))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non-multimetric, don't require refit = True for best_params_ / best_score_\n",
    "class GridSearchCV(GridSearchCVBase):\n",
    "\n",
    "    # For multiple metric evaluation, refit is a string denoting the scorer that should be \n",
    "    # used to find the best parameters for refitting the estimator \n",
    "    @property\n",
    "    def scorer_key(self):\n",
    "        return self.refit if self.multimetric_ else 'score'\n",
    "    \n",
    "    @property\n",
    "    def best_index(self):\n",
    "        check_is_fitted(self, 'cv_results_')\n",
    "        return np.flatnonzero(self.cv_results_['rank_test_{}'.format(self.scorer_key)] == 1)[0]\n",
    "\n",
    "    @property\n",
    "    def best_params_(self):\n",
    "        return self.cv_results_['params'][self.best_index]\n",
    "\n",
    "    @property\n",
    "    def best_score_(self):\n",
    "        return self.cv_results_['mean_test_{}'.format(self.scorer_key)][self.best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {\n",
    "    'fe__d2v__d2v__min_count': [10, 25],\n",
    "    'fe__d2v__d2v__alpha': [0.025, 0.05],\n",
    "    'fe__d2v__d2v__epochs': [10, 20, 30],\n",
    "    'fe__d2v__d2v__vector_size': [200, 300]\n",
    "}\n",
    "            \n",
    "try:\n",
    "    with open('model_param_d2v.yaml', 'r') as f:\n",
    "        param_optimal = yaml.load(f)\n",
    "except IOError:\n",
    "    param_optimal = {}\n",
    "\n",
    "    # create tuner\n",
    "    tuner = GridSearchCV(pipeline, param_grid, scheduler=client_dask, scoring='roc_auc', \n",
    "                         cv=3, refit=False, return_train_score=False)\n",
    "    \n",
    "    # determine optimal hyperparameters\n",
    "    tuner.fit(xdata_train, ydata_train)\n",
    "    print('Best params: %s' % (str(tuner.best_params_)))\n",
    "    print('Best params score: %s' % (str(tuner.best_score_)))\n",
    "    \n",
    "    # save best params\n",
    "    with open('model_param_d2v.yaml', 'w') as f:\n",
    "        yaml.dump(param_optimal, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('fe', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('d2v', Pipeline(memory=None,\n",
       "     steps=[('tk', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x7f500c97bc80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "          va...=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model with optimal param\n",
    "pipeline.set_params(**param_optimal)\n",
    "pipeline.fit(xdata_train, ydata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to eval set\n",
    "ydata_eval_pred = pipeline.predict_proba(xdata_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCs: [0.9171005870841488, 0.9484245700589584, 0.9399900600454398, 0.8828643216080402, 0.9281275901858704, 0.9536998948763655]\n",
      "Avg AUC: 0.9283678373098039\n"
     ]
    }
   ],
   "source": [
    "# calculate auc on eval set\n",
    "auc = [roc_auc_score(ydata_eval[y], ydata_eval_pred[:,i]) for i,y in enumerate(yvar)]\n",
    "print('Model AUCs: %s' % auc)\n",
    "print('Avg AUC: %s' % np.mean(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('fe', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('d2v', Pipeline(memory=None,\n",
       "     steps=[('tk', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x7f500c97bc80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "          va...=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genrate final model\n",
    "pipeline_final = clone(pipeline)\n",
    "pipeline_final.set_params(**param_optimal)\n",
    "pipeline_final.fit(xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output\n",
    "xdata_test = df_test.comment_text\n",
    "ydata_test_pred = pipeline.predict_proba(xdata_test)\n",
    "ydata_test_pred = pd.DataFrame(data=ydata_test_pred, columns=yvar)\n",
    "ydata_test_pred['id'] = df_test.id\n",
    "ydata_test_pred.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
